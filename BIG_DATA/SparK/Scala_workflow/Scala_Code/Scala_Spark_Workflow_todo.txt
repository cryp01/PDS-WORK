
spark-shell

import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.log4j._
import scala.math.min
import org.apache.spark.rdd.RDD.rddToPairRDDFunctions

object WeatherMinimum extends Serializable {
val MISSING = 9999
def main(args:Array[String]) {
var dataFile = "/hduser/input/weather.txt"
val fs = sc.textFile(dataFile)
val splitoutput = fs.map(line => {
val year = line.substring(15, 19)
if(line.length() >= 94) {
val airTemperature = if (line.charAt(87) == '+') line.substring(88, 92) 
else line.substring(87, 92)
val quality = line.substring(92, 93) 
if (Integer.parseInt(airTemperature) != MISSING && "01459".indexOf(quality) >= 0)  (year, airTemperature) 
else (year, Int.MaxValue.toString())
}
})
val stationtemp = splitoutput.map({
case (year, temperature) => year->temperature.asInstanceOf[String].toInt
}) 
val mintempstation = stationtemp.reduceByKey((x, y) => if(x < y) x else y)
val results = mintempstation.collect()
for(result <- results)  println(s"(year, mintemp) is $result")
}}

WeatherMinimum.main(null)
