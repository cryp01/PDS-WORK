[cloudera@quickstart test]$ spark-shell
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel).
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/zookeeper/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/flume-ng/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/parquet/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/avro/avro-tools-1.7.6-cdh5.12.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.6.0
      /_/

Using Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_67)
Type in expressions to have them evaluated.
Type :help for more information.
18/02/03 03:39:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Spark context available as sc (master = local[*], app id = local-1517658018272).
18/02/03 03:40:47 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
SQL context available as sqlContext.

scala> import org.apache.spark._
import org.apache.spark._

scala> import org.apache.spark.SparkContext._
import org.apache.spark.SparkContext._

scala> import org.apache.log4j._
import org.apache.log4j._

scala> import scala.math.min
import scala.math.min

scala> import org.apache.spark.rdd.RDD.rddToPairRDDFunctions
import org.apache.spark.rdd.RDD.rddToPairRDDFunctions

scala> 

scala> object WeatherMinimum extends Serializable {
     | val MISSING = 9999
     | def main(args:Array[String]) {
     | var dataFile = "/hduser/input/weather.txt"
     | val fs = sc.textFile(dataFile)
     | val splitoutput = fs.map(line => {
     | val year = line.substring(15, 19)
     | if(line.length() >= 94) {
     | val airTemperature = if (line.charAt(87) == '+') line.substring(88, 92) 
     | else line.substring(87, 92)
     | val quality = line.substring(92, 93) 
     | if (Integer.parseInt(airTemperature) != MISSING && "01459".indexOf(quality) >= 0)  (year, airTemperature) 
     | else (year, Int.MaxValue.toString())
     | }
     | })
     | val stationtemp = splitoutput.map({
     | case (year, temperature) => year->temperature.asInstanceOf[String].toInt
     | }) 
     | val mintempstation = stationtemp.reduceByKey((x, y) => if(x < y) x else y)
     | val results = mintempstation.collect()
     | for(result <- results)  println(s"(year, mintemp) is $result")
     | }}
defined module WeatherMinimum

scala> 

scala> WeatherMinimum.main(null)
(year, mintemp) is (1901,-333)
