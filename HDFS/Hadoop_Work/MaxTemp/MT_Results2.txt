[cloudera@quickstart MaxTemp]$ export PATH=${JAVA_HOME}/bin:${PATH}
[cloudera@quickstart MaxTemp]$ export HADOOP_CLASSPATH=${JAVA_HOME}/lib/tools.jar
[cloudera@quickstart MaxTemp]$ hadoop com.sun.tools.javac.Main MaxTemperature.java 
Note: MaxTemperature.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
[cloudera@quickstart MaxTemp]$ jar cf mt2.jar MaxTemperature*.class[cloudera@quickstart MaxTemp]$ hadoop jar mt2.jar MaxTemperature /hduser/input/weather.txt /hduser/output16
18/01/20 07:15:06 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
18/01/20 07:15:09 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
18/01/20 07:15:10 INFO input.FileInputFormat: Total input paths to process : 1
18/01/20 07:15:10 INFO mapreduce.JobSubmitter: number of splits:1
18/01/20 07:15:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1516415673782_0003
18/01/20 07:15:13 INFO impl.YarnClientImpl: Submitted application application_1516415673782_0003
18/01/20 07:15:13 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1516415673782_0003/
18/01/20 07:15:13 INFO mapreduce.Job: Running job: job_1516415673782_0003
18/01/20 07:15:44 INFO mapreduce.Job: Job job_1516415673782_0003 running in uber mode : false
18/01/20 07:15:44 INFO mapreduce.Job:  map 0% reduce 0%
18/01/20 07:16:10 INFO mapreduce.Job:  map 100% reduce 0%
18/01/20 07:16:38 INFO mapreduce.Job:  map 100% reduce 100%
18/01/20 07:16:39 INFO mapreduce.Job: Job job_1516415673782_0003 completed successfully
18/01/20 07:16:40 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=72210
		FILE: Number of bytes written=394163
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=888311
		HDFS: Number of bytes written=9
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=22909
		Total time spent by all reduces in occupied slots (ms)=23655
		Total time spent by all map tasks (ms)=22909
		Total time spent by all reduce tasks (ms)=23655
		Total vcore-milliseconds taken by all map tasks=22909
		Total vcore-milliseconds taken by all reduce tasks=23655
		Total megabyte-milliseconds taken by all map tasks=23458816
		Total megabyte-milliseconds taken by all reduce tasks=24222720
	Map-Reduce Framework
		Map input records=6565
		Map output records=6564
		Map output bytes=59076
		Map output materialized bytes=72210
		Input split bytes=121
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=72210
		Reduce input records=6564
		Reduce output records=1
		Spilled Records=13128
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=644
		CPU time spent (ms)=7560
		Physical memory (bytes) snapshot=358330368
		Virtual memory (bytes) snapshot=3015155712
		Total committed heap usage (bytes)=226365440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=888190
	File Output Format Counters 
		Bytes Written=9
[cloudera@quickstart MaxTemp]$ hdfs dfs -ls /hduser/output16
Found 2 items
-rw-r--r--   1 cloudera supergroup          0 2018-01-20 07:16 /hduser/output16/_SUCCESS
-rw-r--r--   1 cloudera supergroup          9 2018-01-20 07:16 /hduser/output16/part-r-00000
[cloudera@quickstart MaxTemp]$ hdfs dfs -cat /hduser/output16/part-r-00000
1901	317
